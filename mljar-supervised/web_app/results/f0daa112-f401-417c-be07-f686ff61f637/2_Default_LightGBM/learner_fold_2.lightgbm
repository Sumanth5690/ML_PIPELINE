tree
version=v4
num_class=1
num_tree_per_iteration=1
label_index=0
max_feature_idx=29
objective=regression
feature_names=Column_0 Column_1 Column_2 Column_3 Column_4 Column_5 Column_6 Column_7 Column_8 Column_9 Column_10 Column_11 Column_12 Column_13 Column_14 Column_15 Column_16 Column_17 Column_18 Column_19 Column_20 Column_21 Column_22 Column_23 Column_24 Column_25 Column_26 Column_27 Column_28 Column_29
feature_infos=[2.1899999999999999:4996.7700000000004] [-2.9015240000000002:3.0871550000000001] [-2.9530750000000001:3.260491] [-2.6359680000000001:3.657702] [-3.7087970000000001:2.72736] [-3.064457:3.5994670000000002] [-2.8147150000000001:3.5556169999999998] [-3.4089670000000001:3.0934300000000001] [-4.0540500000000002:3.0517110000000001] [-2.706518:2.7845879999999998] [-3.1747489999999998:3.155538] [-2.9422540000000001:3.1011869999999999] [-2.9309310000000002:3.0654750000000002] [-2.8196859999999999:2.5595620000000001] [-3.1046049999999998:3.2160199999999999] [-2.957525:2.659996] [-3.4897800000000001:3.3176869999999998] [-2.697479:2.7323620000000002] [-3.036178:2.7773530000000002] [-3.2646359999999999:2.7634989999999999] [-3.053153:3.9027989999999999] [-2.755369:3.5886809999999998] [-2.9122379999999999:2.915063] [-3.144962:3.9385029999999999] [-2.750909:3.4027379999999998] [-3.091996:2.8213029999999999] [-3.5927470000000001:3.1989800000000002] [-3.3637260000000002:2.9922309999999999] [-3.5433189999999999:3.2020010000000001] [0:1]
tree_sizes=6276

Tree=0
num_leaves=63
num_cat=0
split_feature=6 27 16 25 0 10 25 0 19 15 4 23 16 19 2 23 1 11 15 9 7 11 7 4 8 21 0 3 10 9 15 14 10 12 27 27 3 21 17 27 15 26 17 7 19 14 17 26 1 11 21 6 18 26 3 18 17 18 0 22 2 6
split_gain=11.3953 9.9346 15.3164 10.9096 12.1731 8.8957 8.00478 7.83137 6.96134 7.04485 10.5506 6.64173 6.59302 6.31458 9.65707 5.49986 5.65812 4.94482 9.6009 4.84667 7.67656 6.47245 5.88163 4.97934 5.58423 6.24136 5.25603 5.0999 4.4507 6.99138 3.655 3.48442 3.30069 3.0392 2.42123 2.28869 2.58866 2.80956 2.05539 2.76547 3.22643 2.02107 2.44212 1.58854 1.44073 1.1868 1.1523 0.962588 0.871202 0.735698 0.58007 0.490431 0.759974 0.735931 0.479827 0.569278 0.456016 0.374096 0.271181 0.251924 0.171219 0.109203
threshold=1.0102545000000001 0.51240450000000004 -1.4526454999999998 1.3973690000000001 2119.4300000000007 -1.1487659999999997 -1.8342835 2984.2350000000001 -1.2794294999999998 -0.15604349999999997 -0.006317999999999999 -0.070937499999999987 -0.42971899999999996 0.88529300000000011 1.2269265000000003 0.69185550000000007 0.33949150000000006 1.2377470000000002 0.91769200000000006 -0.87479599999999991 0.43151000000000006 -0.021488499999999997 -0.93875199999999992 -0.056699499999999993 0.31896200000000002 -0.63625999999999994 2532.8600000000006 0.31133450000000007 0.52868150000000014 0.66880500000000009 1.4952105000000002 -1.1151854999999997 -0.47677149999999996 0.081025000000000014 1.4464470000000003 1.4854345000000002 0.66876600000000008 -0.0094404999999999992 0.94508150000000002 0.16800750000000003 -1.0895184999999998 -0.85524899999999981 0.36262500000000003 0.42382000000000003 -1.0328629999999996 -0.46580849999999996 0.16124750000000002 1.3187090000000004 1.5211805000000003 0.92675750000000012 -0.55063149999999983 -0.61619599999999985 0.74927250000000012 -0.49331499999999995 -0.84047549999999993 -0.123512 -0.025257999999999996 0.40902500000000003 3467.5850000000005 0.32419400000000004 0.28080700000000008 1.4644560000000002
decision_type=2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
left_child=1 3 -3 6 -5 12 -1 -6 9 -8 -11 35 -4 14 15 16 -13 19 33 20 22 -22 -10 30 38 -26 -27 -28 29 41 31 -21 -31 -19 46 36 37 -7 39 40 -25 -2 54 57 -30 -24 -17 48 49 50 -33 -52 53 -53 -43 -56 -47 -42 61 -55 -57 -46
right_child=28 2 5 4 7 11 8 -9 17 10 -12 13 -14 -15 -16 34 -18 18 -20 23 21 -23 45 24 25 26 27 -29 44 32 -32 47 -34 -35 -36 -37 -38 -39 -40 -41 43 42 -44 -45 58 56 -48 -49 -50 -51 51 52 -54 59 55 60 -58 -59 -60 -61 -62 -63
leaf_value=-0.028436658536198884 -0.0032014767630495879 -0.06972421509836832 -0.0050401947910722802 -0.071948325585835846 0.020722317488745406 -0.01337857538363702 0.015499446042861869 -0.032299005390717263 -0.014846992465874577 -0.067751335670248158 -0.0023150396237906529 -0.0041978741127464804 -0.057452912654989641 0.014883671916759341 -0.06541490967225401 0.023039690561669292 -0.049265838080658195 -0.012270059756265255 -0.052147382449620638 -0.0061839202377516568 -0.0050291940877094229 -0.05572380552839605 0.0085241980835659599 -0.011160776864999207 0.020089044996940565 -0.043204444959888601 -0.028088004882963348 0.020059040413060839 0.010599835153407186 0.0014615137052896893 -0.010647564957180293 0.016219333099870708 -0.039162926774733937 0.017679643049988144 -0.018019873265438947 -0.0066426315147500173 0.030197680026030866 0.018220406909813924 0.030520616009037313 -0.012265306200473182 0.035384048892544033 0.01600833629418048 0.0033165611104696946 0.0097420414960039427 0.031871240485197613 0.035957572061306557 -0.00041160415697959256 0.010405164764502284 0.010790754865593045 0.039134379375464053 0.033624146256333941 0.009442559844425321 0.033603547064946421 0.020348189464006794 0.018914553049689857 0.038151747036463318 0.021500490976856475 0.022618525661964668 0.025648892979806989 0.030629346134387149 0.028899219233280746 0.03909061986689763
leaf_weight=19 12.999999999999998 10.999999999999998 10.000000000000002 9.9999999999999982 13.000000000000002 12.000000000000002 11.999999999999998 14.999999999999998 17 11 14 13.000000000000002 14.999999999999998 15.999999999999998 9.9999999999999982 11.000000000000005 14.999999999999998 15.999999999999998 9.9999999999999982 10.999999999999998 17.000000000000004 9.9999999999999982 11.999999999999998 9.9999999999999982 13.999999999999998 13.999999999999998 11.000000000000002 10.999999999999998 9.9999999999999982 10.000000000000002 9.9999999999999982 15.999999999999998 9.9999999999999982 18 9.9999999999999982 19 15.999999999999998 17 13.999999999999998 11.999999999999998 12.000000000000002 9.9999999999999982 18 19 10.000000000000005 10 9.9999999999999982 12.999999999999998 9.9999999999999982 9.9999999999999982 18.999999999999986 10.999999999999984 14.999999999999998 13.00000000000003 9.9999999999999982 10.000000000000005 12 10.999999999999998 9.9999999999999982 10.999999999999998 9.9999999999999982 10.999999999999998
leaf_count=19 13 11 10 10 13 12 12 15 17 11 14 13 15 16 10 11 15 16 10 11 17 10 12 10 14 14 11 11 10 10 10 16 10 18 10 19 16 17 14 12 12 10 18 19 10 10 10 13 10 10 19 11 15 13 10 10 12 11 10 11 10 11
internal_value=-2.62276e-10 -0.00265269 -0.0125052 0.00112102 -0.0245942 -0.00888786 0.00331693 -0.00768196 0.00473316 -0.0159914 -0.031107 -0.00425699 -0.0364878 -0.013417 -0.0199795 -0.0122786 -0.0283414 0.0067044 -0.00908094 0.0087176 -0.00224694 -0.023805 0.00916614 0.0119207 0.00480527 -0.00823868 -0.019255 -0.00401448 0.0134242 0.00726158 0.0184731 0.0207305 -0.0188507 0.00358567 0.00222974 0.0079087 0.0140526 0.00514497 0.0131668 0.00937062 0.0143635 0.0146171 0.018611 0.0204407 0.0271024 0.0211727 0.0118724 0.0232395 0.0248285 0.0263061 0.0247969 0.0267859 0.0241874 0.0201519 0.0254935 0.0286552 0.0280719 0.0292788 0.0324257 0.0250604 0.0335255 0.0356528
internal_weight=800 668 185 483 38 174 445 28 426 37 25 149 25 85 69 59 28 389 44 345 78 27 51 267 128 50 36 22 132 91 139 129 20 34 31 64 45 29 78 64 52 71 58 42 41 34 21 118 105 95 85 69 50 35 40 30 22 23 31 24 20 21
internal_count=800 668 185 483 38 174 445 28 426 37 25 149 25 85 69 59 28 389 44 345 78 27 51 267 128 50 36 22 132 91 139 129 20 34 31 64 45 29 78 64 52 71 58 42 41 34 21 118 105 95 85 69 50 35 40 30 22 23 31 24 20 21
is_linear=0
shrinkage=1


end of trees

feature_importances:
Column_0=4
Column_15=4
Column_17=4
Column_27=4
Column_3=3
Column_6=3
Column_7=3
Column_10=3
Column_11=3
Column_18=3
Column_19=3
Column_21=3
Column_26=3
Column_1=2
Column_2=2
Column_4=2
Column_9=2
Column_14=2
Column_16=2
Column_23=2
Column_25=2
Column_8=1
Column_12=1
Column_22=1

parameters:
[boosting: gbdt]
[objective: regression]
[metric: rmse]
[tree_learner: serial]
[device_type: cpu]
[data_sample_strategy: bagging]
[data: ]
[valid: ]
[num_iterations: 10000]
[learning_rate: 0.05]
[num_leaves: 63]
[num_threads: 0]
[seed: 2]
[deterministic: 0]
[force_col_wise: 0]
[force_row_wise: 0]
[histogram_pool_size: -1]
[max_depth: -1]
[min_data_in_leaf: 10]
[min_sum_hessian_in_leaf: 0.001]
[bagging_fraction: 0.9]
[pos_bagging_fraction: 1]
[neg_bagging_fraction: 1]
[bagging_freq: 0]
[bagging_seed: 29216]
[bagging_by_query: 0]
[feature_fraction: 0.9]
[feature_fraction_bynode: 1]
[feature_fraction_seed: 17795]
[extra_trees: 0]
[extra_seed: 19650]
[early_stopping_round: 0]
[early_stopping_min_delta: 0]
[first_metric_only: 0]
[max_delta_step: 0]
[lambda_l1: 0]
[lambda_l2: 0]
[linear_lambda: 0]
[min_gain_to_split: 0]
[drop_rate: 0.1]
[max_drop: 50]
[skip_drop: 0.5]
[xgboost_dart_mode: 0]
[uniform_drop: 0]
[drop_seed: 24198]
[top_rate: 0.2]
[other_rate: 0.1]
[min_data_per_group: 100]
[max_cat_threshold: 32]
[cat_l2: 10]
[cat_smooth: 10]
[max_cat_to_onehot: 4]
[top_k: 20]
[monotone_constraints: ]
[monotone_constraints_method: basic]
[monotone_penalty: 0]
[feature_contri: ]
[forcedsplits_filename: ]
[refit_decay_rate: 0.9]
[cegb_tradeoff: 1]
[cegb_penalty_split: 0]
[cegb_penalty_feature_lazy: ]
[cegb_penalty_feature_coupled: ]
[path_smooth: 0]
[interaction_constraints: ]
[verbosity: -1]
[saved_feature_importance_type: 0]
[use_quantized_grad: 0]
[num_grad_quant_bins: 4]
[quant_train_renew_leaf: 0]
[stochastic_rounding: 1]
[linear_tree: 0]
[max_bin: 255]
[max_bin_by_feature: ]
[min_data_in_bin: 3]
[bin_construct_sample_cnt: 200000]
[data_random_seed: 45]
[is_enable_sparse: 1]
[enable_bundle: 1]
[use_missing: 1]
[zero_as_missing: 0]
[feature_pre_filter: 1]
[pre_partition: 0]
[two_round: 0]
[header: 0]
[label_column: ]
[weight_column: ]
[group_column: ]
[ignore_column: ]
[categorical_feature: ]
[forcedbins_filename: ]
[precise_float_parser: 0]
[parser_config_file: ]
[objective_seed: 29484]
[num_class: 1]
[is_unbalance: 0]
[scale_pos_weight: 1]
[sigmoid: 1]
[boost_from_average: 1]
[reg_sqrt: 0]
[alpha: 0.9]
[fair_c: 1]
[poisson_max_delta_step: 0.7]
[tweedie_variance_power: 1.5]
[lambdarank_truncation_level: 30]
[lambdarank_norm: 1]
[label_gain: ]
[lambdarank_position_bias_regularization: 0]
[eval_at: ]
[multi_error_top_k: 1]
[auc_mu_weights: ]
[num_machines: 1]
[local_listen_port: 12400]
[time_out: 120]
[machine_list_filename: ]
[machines: ]
[gpu_platform_id: -1]
[gpu_device_id: -1]
[gpu_use_dp: 0]
[num_gpu: 1]

end of parameters

pandas_categorical:null
