tree
version=v4
num_class=1
num_tree_per_iteration=1
label_index=0
max_feature_idx=29
objective=regression
feature_names=Column_0 Column_1 Column_2 Column_3 Column_4 Column_5 Column_6 Column_7 Column_8 Column_9 Column_10 Column_11 Column_12 Column_13 Column_14 Column_15 Column_16 Column_17 Column_18 Column_19 Column_20 Column_21 Column_22 Column_23 Column_24 Column_25 Column_26 Column_27 Column_28 Column_29
feature_infos=[2.1899999999999999:4996.7700000000004] [-2.9015240000000002:3.0871550000000001] [-2.9530750000000001:3.260491] [-2.6359680000000001:3.657702] [-3.7087970000000001:2.72736] [-3.064457:3.5994670000000002] [-2.8147150000000001:3.5556169999999998] [-3.4089670000000001:3.0934300000000001] [-4.0540500000000002:3.0517110000000001] [-2.706518:2.7845879999999998] [-3.1747489999999998:3.155538] [-2.9422540000000001:3.1011869999999999] [-2.9309310000000002:3.0654750000000002] [-2.8196859999999999:2.5595620000000001] [-3.1046049999999998:3.2160199999999999] [-2.957525:2.659996] [-3.4897800000000001:3.3176869999999998] [-2.697479:2.7323620000000002] [-3.036178:2.7773530000000002] [-3.2646359999999999:2.7634989999999999] [-3.053153:3.9027989999999999] [-2.755369:3.5886809999999998] [-2.9122379999999999:2.915063] [-3.144962:3.9385029999999999] [-2.750909:3.4027379999999998] [-3.091996:2.8213029999999999] [-3.5927470000000001:3.1989800000000002] [-3.3637260000000002:2.9922309999999999] [-3.5433189999999999:3.2020010000000001] [0:1]
tree_sizes=6243

Tree=0
num_leaves=62
num_cat=0
split_feature=16 19 15 16 24 27 24 10 10 24 11 20 27 7 11 20 19 17 19 15 10 11 7 27 28 10 24 28 8 15 16 10 8 11 28 10 28 7 8 20 11 15 12 15 11 12 17 17 19 17 4 19 27 12 20 8 12 4 4 10 20
split_gain=7.51034 7.01261 8.89767 9.51969 5.54048 8.85485 7.31546 7.94071 10.9594 9.53882 5.1984 4.69002 4.59095 5.18005 4.44261 12.6716 4.39788 3.76661 3.85025 3.48062 4.36568 3.64369 3.28443 3.35567 3.01984 5.09271 5.56522 3.01385 4.3758 5.45524 2.87424 2.6643 3.67551 2.86572 4.29391 6.48396 2.85099 2.29082 2.02892 1.93358 1.84216 1.82986 1.92458 1.31111 1.23484 1.03973 1.03613 0.975641 0.926518 0.817551 0.813609 0.747075 0.692839 0.688832 0.707051 0.594712 0.566643 0.345794 0.336851 0.410867 0.10187
threshold=-2.1606349999999996 -0.17313999999999999 1.5732110000000001 -1.5574904999999999 1.0497345000000002 1.6650305000000001 0.94324300000000016 -0.17791199999999999 -0.52506549999999985 0.0069990000000000009 -0.33356649999999993 0.87769850000000005 1.3753095000000002 -0.14332649999999997 -1.6448064999999998 0.11711350000000001 -0.36683649999999995 1.0453150000000002 -0.49116849999999995 -1.2895929999999998 -0.70307649999999988 0.13627000000000003 0.34346650000000006 -0.24073649999999996 -1.0378029999999998 -0.039735499999999993 0.36394200000000004 -0.70781549999999982 1.1202070000000002 0.10075200000000002 -0.75617749999999984 -1.2125404999999996 0.25457300000000005 -0.032406999999999991 0.054381000000000006 0.24790000000000004 -0.28587099999999993 -0.49169449999999998 -1.2629604999999999 0.85096450000000012 0.22505000000000003 0.28197050000000007 0.10353800000000002 0.35740450000000007 1.2377470000000002 -0.60866049999999994 -0.034616999999999988 -1.0000000180025095e-35 -0.94234899999999988 0.16919800000000004 1.0000000180025095e-35 -0.93682599999999983 -0.18890649999999998 -0.82607999999999993 0.81154150000000014 -0.47442449999999997 0.79513450000000019 0.69826200000000016 -0.59519699999999987 0.32734400000000002 -0.031001999999999998
decision_type=2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2
left_child=-1 2 3 -2 5 6 7 8 11 -10 39 16 14 -14 15 -3 37 18 22 20 -16 -22 23 43 25 50 -27 52 31 -30 -6 32 -29 41 35 36 -35 -5 -36 48 -15 49 47 -12 53 -32 -20 -43 -9 57 -21 -47 -26 -40 -55 -51 -39 58 -33 -60 -50
right_child=1 12 -4 4 30 -7 -8 10 9 -11 17 -13 13 40 19 -17 -18 -19 46 24 21 -23 -24 -25 27 26 -28 28 29 -31 45 33 -34 34 38 -37 -38 56 44 -41 -42 42 -44 -45 -46 51 -48 -49 60 55 -52 -53 -54 54 -56 -57 -58 -59 59 -61 -62
leaf_value=-0.1570316957945761 -0.15738859822046569 -0.20405342156838738 -0.16002556621156094 -0.008778879525545142 -0.032983351816431181 -0.17625980241708863 -0.17453391733419268 0.071723502810782533 -0.056841270099345503 -0.2932392294900571 0.087281145153926182 -0.085634247581099193 -0.12102321160355994 -0.041479011874907878 -0.13126092280101148 0.080952689718766263 -0.081815848004334848 0.10836047567276789 0.089648687802525384 0.098023101437574922 -0.050994073476904295 0.086212747452518682 -0.11420074599196704 -0.075597915215570119 0.14814396574942895 -0.18978781844329198 0.016362686611788708 0.056861338686509173 -0.10582246203856328 0.080341026868409243 0.13487418621176567 0.13430220026259618 -0.10022069972271724 0.10540499284713101 -0.015655149992817318 -0.10786291046425403 -0.022559463081426936 0.064363256804915295 0.13307178591538107 0.008183967221266358 0.069727752222489267 0.10985852408382926 -0.01145085627984372 -0.010773825597279938 0.023524101235049208 0.10613570665169392 0.0076234828552829087 0.036094869423395709 0.12202011500645313 0.032843264184630232 0.020780187160756518 0.037956058885691965 0.078653851849865702 0.051396602539704545 0.1200528067832056 0.097717982051488864 0.12126633968231286 0.14896158789444597 0.062063221607095286 0.11939502214241657 0.1505676052455964
leaf_weight=11.999999999999998 17 12.000000000000002 17 12.999999999999998 10.999999999999998 12.999999999999998 9.9999999999999982 15.999999999999995 18.000000000000004 10.999999999999998 11.999999999999995 19 19 11.000000000000002 10.999999999999998 12.999999999999998 10.999999999999998 11.999999999999998 14.000000000000002 10.000000000000002 16.000000000000004 14.999999999999998 17 17 12.000000000000002 10.000000000000002 10.999999999999998 13.000000000000002 17.000000000000004 9.9999999999999982 10.999999999999998 10.999999999999998 10.999999999999998 15.000000000000002 9.9999999999999982 18 12.999999999999998 14.000000000000002 14.999999999999995 9.9999999999999982 12.999999999999998 15.999999999999998 14.999999999999998 9.9999999999999982 10.999999999999998 9.9999999999999982 11.000000000000005 13.000000000000002 9.9999999999999982 10.000000000000002 11.999999999999998 18.000000000000004 10.999999999999998 15.000000000000005 9.9999999999999982 12.999999999999998 13.999999999999998 9.9999999999999982 10.000000000000005 9.9999999999999982 10.000000000000005
leaf_count=12 17 12 17 13 11 13 10 16 18 11 12 19 19 11 11 13 11 12 14 10 16 15 17 17 12 10 11 13 17 10 11 11 11 15 10 18 13 14 15 10 13 16 15 10 11 10 11 13 10 10 12 18 11 15 10 13 14 10 10 10 10
internal_value=-2.99537e-10 0.00239135 -0.0189332 -0.0116427 -0.00370143 -0.0153443 -0.0069431 6.90641e-05 -0.0429111 -0.146509 0.03099 -0.000596283 0.0190843 -0.0430058 0.0257757 -0.0558502 0.0304753 0.00378843 -0.0117037 0.031232 -0.0230139 0.0153963 -0.0408382 -0.00885972 0.0380944 -0.0113557 -0.0818042 0.0454521 0.0394464 -0.036873 0.0573073 0.0480682 -0.0151346 0.0551234 0.0319256 -0.0142115 0.0459929 0.0606022 0.0667175 0.0859846 0.018758 0.0781064 0.0467092 0.0427107 0.082869 0.0827739 0.0535576 0.0767921 0.107596 0.099692 0.0558906 0.0623059 0.11491 0.0991888 0.0788591 0.0695116 0.0928148 0.116623 0.106191 0.0907291 0.136294
internal_weight=800 788 346 329 312 262 249 239 100 29 139 71 442 43 399 25 52 93 81 374 42 31 56 39 332 43 21 289 266 27 50 239 24 215 107 46 28 41 61 46 24 108 44 22 51 39 25 29 36 64 22 28 23 40 25 23 28 41 31 20 20
internal_count=800 788 346 329 312 262 249 239 100 29 139 71 442 43 399 25 52 93 81 374 42 31 56 39 332 43 21 289 266 27 50 239 24 215 107 46 28 41 61 46 24 108 44 22 51 39 25 29 36 64 22 28 23 40 25 23 28 41 31 20 20
is_linear=0
shrinkage=1


end of trees

feature_importances:
Column_10=7
Column_11=6
Column_15=5
Column_19=5
Column_20=5
Column_8=4
Column_12=4
Column_17=4
Column_24=4
Column_27=4
Column_28=4
Column_4=3
Column_7=3
Column_16=3

parameters:
[boosting: gbdt]
[objective: regression]
[metric: rmse]
[tree_learner: serial]
[device_type: cpu]
[data_sample_strategy: bagging]
[data: ]
[valid: ]
[num_iterations: 10000]
[learning_rate: 0.2]
[num_leaves: 63]
[num_threads: 0]
[seed: 1236]
[deterministic: 0]
[force_col_wise: 0]
[force_row_wise: 0]
[histogram_pool_size: -1]
[max_depth: -1]
[min_data_in_leaf: 10]
[min_sum_hessian_in_leaf: 0.001]
[bagging_fraction: 1]
[pos_bagging_fraction: 1]
[neg_bagging_fraction: 1]
[bagging_freq: 0]
[bagging_seed: 21709]
[bagging_by_query: 0]
[feature_fraction: 0.5]
[feature_fraction_bynode: 1]
[feature_fraction_seed: 24116]
[extra_trees: 0]
[extra_seed: 15571]
[early_stopping_round: 0]
[early_stopping_min_delta: 0]
[first_metric_only: 0]
[max_delta_step: 0]
[lambda_l1: 0]
[lambda_l2: 0]
[linear_lambda: 0]
[min_gain_to_split: 0]
[drop_rate: 0.1]
[max_drop: 50]
[skip_drop: 0.5]
[xgboost_dart_mode: 0]
[uniform_drop: 0]
[drop_seed: 15722]
[top_rate: 0.2]
[other_rate: 0.1]
[min_data_per_group: 100]
[max_cat_threshold: 32]
[cat_l2: 10]
[cat_smooth: 10]
[max_cat_to_onehot: 4]
[top_k: 20]
[monotone_constraints: ]
[monotone_constraints_method: basic]
[monotone_penalty: 0]
[feature_contri: ]
[forcedsplits_filename: ]
[refit_decay_rate: 0.9]
[cegb_tradeoff: 1]
[cegb_penalty_split: 0]
[cegb_penalty_feature_lazy: ]
[cegb_penalty_feature_coupled: ]
[path_smooth: 0]
[interaction_constraints: ]
[verbosity: -1]
[saved_feature_importance_type: 0]
[use_quantized_grad: 0]
[num_grad_quant_bins: 4]
[quant_train_renew_leaf: 0]
[stochastic_rounding: 1]
[linear_tree: 0]
[max_bin: 255]
[max_bin_by_feature: ]
[min_data_in_bin: 3]
[bin_construct_sample_cnt: 200000]
[data_random_seed: 4074]
[is_enable_sparse: 1]
[enable_bundle: 1]
[use_missing: 1]
[zero_as_missing: 0]
[feature_pre_filter: 1]
[pre_partition: 0]
[two_round: 0]
[header: 0]
[label_column: ]
[weight_column: ]
[group_column: ]
[ignore_column: ]
[categorical_feature: ]
[forcedbins_filename: ]
[precise_float_parser: 0]
[parser_config_file: ]
[objective_seed: 10917]
[num_class: 1]
[is_unbalance: 0]
[scale_pos_weight: 1]
[sigmoid: 1]
[boost_from_average: 1]
[reg_sqrt: 0]
[alpha: 0.9]
[fair_c: 1]
[poisson_max_delta_step: 0.7]
[tweedie_variance_power: 1.5]
[lambdarank_truncation_level: 30]
[lambdarank_norm: 1]
[label_gain: ]
[lambdarank_position_bias_regularization: 0]
[eval_at: ]
[multi_error_top_k: 1]
[auc_mu_weights: ]
[num_machines: 1]
[local_listen_port: 12400]
[time_out: 120]
[machine_list_filename: ]
[machines: ]
[gpu_platform_id: -1]
[gpu_device_id: -1]
[gpu_use_dp: 0]
[num_gpu: 1]

end of parameters

pandas_categorical:null
